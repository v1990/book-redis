{"./":{"url":"./","title":"介绍","keywords":"","body":"redis学习笔记redis学习笔记 "},"basic/":{"url":"basic/","title":"原理与实现","keywords":"","body":"原理与实现单线程架构原理与实现 单线程架构 一条命令到达服务端之后不会立刻被执行， 所有命令都会进入一个队列中， 然后逐个被执行。 redis单线程原因： 纯内存访问 非阻塞IO，使用epoll作为IO多路复用模型，加上redis自身的事件处理模型将epoll中的连接/读写/关闭都转换为事件，不在网络IO上浪费过多的时间 单线程避免了线程切换和竟态产生的消耗 单线程问题： 对于每个命令的执行时间有要求，如果一个命令执行时间过长，会造成其他命令的阻塞 所以redis是面向快速执行场景的数据库 "},"basic/install.html":{"url":"basic/install.html","title":"安装","keywords":"","body":"安装安装 "},"commands/":{"url":"commands/","title":"命令","keywords":"","body":"命令命令 string hash list set zset slowlog transaction script bitmaps hyperLogLog pub geo "},"commands/string.html":{"url":"commands/string.html","title":"string","keywords":"","body":"stringstring "},"commands/hash.html":{"url":"commands/hash.html","title":"hash","keywords":"","body":"hashhash "},"commands/list.html":{"url":"commands/list.html","title":"list","keywords":"","body":"listlist "},"commands/set.html":{"url":"commands/set.html","title":"set","keywords":"","body":"setset "},"commands/zset.html":{"url":"commands/zset.html","title":"zset","keywords":"","body":"zsetzset "},"commands/slowlog.html":{"url":"commands/slowlog.html","title":"slowlog","keywords":"","body":"slowlogslowlog "},"commands/transaction.html":{"url":"commands/transaction.html","title":"transaction","keywords":"","body":"transactiontransaction "},"commands/script.html":{"url":"commands/script.html","title":"script","keywords":"","body":"scriptscript "},"commands/bitmaps.html":{"url":"commands/bitmaps.html","title":"bitmaps","keywords":"","body":"bitmapsbitmaps "},"commands/hyperLogLog.html":{"url":"commands/hyperLogLog.html","title":"hyperLogLog","keywords":"","body":"hyperLogLoghyperLogLog "},"commands/pub-sub.html":{"url":"commands/pub-sub.html","title":"pub","keywords":"","body":"pubpub "},"commands/geo.html":{"url":"commands/geo.html","title":"geo","keywords":"","body":"geogeo "},"persistence/":{"url":"persistence/","title":"持久化","keywords":"","body":"持久化持久化 "},"replication/":{"url":"replication/","title":"主从复制","keywords":"","body":"主从复制主从复制 "},"sentinel/":{"url":"sentinel/","title":"哨兵","keywords":"","body":"哨兵哨兵 "},"cluster/":{"url":"cluster/","title":"集群","keywords":"","body":"集群数据分布集群功能的限制搭建集群1. 准备节点2. 节点握手3. 分配槽4. 配置从节点官方集群搭建工具：redis-trib.rb节点通信通信过程：Gossip消息节点选择集群伸缩扩容集群收缩集群请求路由MOVED重定向smart客户端ASK重定向故障转移故障发现故障恢复集群运维集群完成性带宽消耗pub/sub广播问题集群倾斜集群读写分离手动故障转移redis集群工具：redis-trib.rb集群 数据分布 节点取余分区 分区公式：hash(key)%N,但是当节点数量N调整时，数据节点的映射关系需要重新计算，会导致数据的重新迁移 一致性hash分区 实现思路：为系统中的每个节点分配一个token，这些token构成一个哈希环，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点 缺点： 加减节点会造成哈希环中部分数据无法命中，需要手动处理或者忽略这部分数据，因此一致性哈希双方常用于缓存场景 当使用少量节点时，节点变化将大范围影响哈希环中的数据映射，因此这种方式不适合少量数据节点的分布式方案 普通的一致性哈希分区在增减节点时需要增加一倍或较少一半节点才能保证数据和负载的均衡 虚拟槽分区 基于hash分区，使用分散度良好的哈希函数将所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）； 这个范围一般远远大于节点数； 槽是集群内数据管理和迁移的基本单位，采用大范围槽的主要目的是为了方便数据拆分和集群扩展； 每个节点会负责一定数量的槽 redis cluser 采用虚拟槽分区，计算公式:slot=CRC16(key)&16383 特点： 解耦数据与节点之间的关系，简化了节点扩容和收缩的难度 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区的元数据 支持节点，槽，键之间的映射查询，用于数据路由，在线伸缩灯场景 集群功能的限制 key批量操作：如mset,mget；目前只支持相同slot值的key执行批量操作 key事务操作：同理只支持相同slot的多个key在同一节点上的事务操作 key作为数据分区的最小粒度，因此不能将一个大的对象（如hash，list）等映射到不同的节点上 不支持多数据库空间：集群模式下只能使用一个数据空间，即 db 0； 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构 搭建集群 1. 准备节点 至少6个； conf开启集群模式 # 节点端口 port xxxx # 开启集群模式 cluster-enabled yes # 节点超时时间，毫秒 cluster-node-timeout 15000 # 集群内部配置文件（不存在会自动创建） cluster-config-file \"conf/nodes-xxx.conf\" 启动所有节点 redis-server conf/redis-6379.conf redis-server conf/redis-6380.conf redis-server conf/redis-6381.conf ... 2. 节点握手 节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程 客户端发起命令: 客户端向节点6379发起命令：cluster meet 127.0.0.1 6380,让节点6379与6380节点进行握手通信，cluster meet是一条异步命令，执行后立刻返回，然后内部发起与目标节点进行握手通信，过程如下： 节点6379本地创建6380节点信息对象，并发送meet消息 节点6380收到meet消息后，保存6379节点信息并回复pong消息 之后节点6379和6380彼此定期通过ping/pong消息进程正常的节点通信 客户点继续向6379节点发起meet命令让其他节点也加入到集群中 向各个节点分别执行cluster nodes命令，可以看到它们彼此已经感知到对方的存在 节点建立握手后集群还不能正常工作，这时集群处于下线状态，所有的数据读写都被禁止； 可以通过cluster info命令获取集群的当前状态 3. 分配槽 通过cluster addslots命令为节点分配槽 redis-cli h 127.0.0.1 -p 6379 cluster addslots {0...5461} redis-cli h 127.0.0.1 -p 6380 cluster addslots {5462...10922} redis-cli h 127.0.0.1 -p 6381 cluster addslots {10923...16383} 此时集群进入在线状态，所有槽都已经分配给节点 执行cluster info命令查看集群状态 执行cluster nodes查看节点和槽的分配关系 4. 配置从节点 首次启动的节点和被分配槽的节点都是主节点 从节点负责复制主节点槽信息和相关数据 使用cluster replicate [nodeId]命令让一个节点成为从节点；nodeId为要复制的主节点id（使用cluster nodes查看主节点id） redis-cli h 127.0.0.1 -p 6382 cluster replicate \"$node_id_6379\" redis-cli h 127.0.0.1 -p 6383 cluster replicate \"$node_id_6380\" redis-cli h 127.0.0.1 -p 6384 cluster replicate \"$node_id_6381\" 再次通过cluster nodes查看集群状态和复制关系； 目前，此集群由6个节点构成， 3个主节点负责处理槽和相关数据， 3个从节点负责故障转移 官方集群搭建工具：redis-trib.rb 节点通信 元数据：节点负责哪些槽，哪些数据，是否出现故障等状态信息 常见的元数据维护方式分为：集中式和P2P方式 redis集群采用P2P的Gossip协议,Gossip协议工作原理就是节点彼此不断通信交换信息，一段时间后所有节点就会知道集群完整的信息，这种方式类似于流言传播； 通信过程： 集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口加上10000（如6380的通信端口为16380） 每个节点在固定周期内通过特定规则选择几个节点发送ping消息 接收到ping消息的节点回复pong响应 集群中的每个节点通过一定规则挑选要通信的节点，每个节点可能知道全部节点，也可能知道部分节点，只要这些节点彼此可以正常通信，最终他们会达到一致的状态。 当节点故障/新节点加入/主从角色变化/槽信息变更等事件发生时，通过不断的ping/pong消息通信，经过一段时间后所有节点都会知道整个集群的全部节点的最新状态， 从而达到集群同步的目的Gossip消息 Gossip协议的主要职责就是信息交换，信息交换的载体就是节点彼此发送的消息 常用的Gossip消息可分为： meet：用于通知新节点加入 ping：集群内交换最频繁的消息，集群每个节点每秒向多个节点发送ping消息，用于检测节点是否在线和交换彼此状态信息 pong：当接收到ping，meet消息时，作为响应消息给发送方确认消息正常通行，pong消息内部封装了自身状态数据，节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新 fail：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态节点选择 redis集群内节点通信采用固定频率（定时任务：10次/秒）通过ping/pong进行节点消息交换 节点选择规则为： 每秒随机5次找出最久没通信的节点 最后通信时间大于node-timeout/2 发送的ping消息包括节点自身消息和1/10其他节点消息 集群伸缩 扩容集群 启动新节点: redis-server conf/redis_6385.conf 加入集群： redis-cli h 127.0.0.1 -p 6379 cluster meet 127.0.0.1 6385 新节点刚开始都是主节点状态，但是由于没有负责的槽，所以不能接受任何的读写操作 所以它一般有两种选择： 为它迁移槽和数据实现扩容 作为其他主节点的从节点负责故障转移 可以用redis-trib.rb工具添加节点： usage: redis-trib.rb add-node new_host:now_port existing_host:existing_port --slave --master-id example: redis-trib.rb add-node 127.0.0.1:6385 127.0.0.1:6379 迁移槽和数据 redis-trib.rb工具提供了槽重分片的功能: usage:redis-trib.rb reshared host:port --from -- to --slots --yes --timeout --pipeline host:port：必传，集群内任意节点地址 --from:源节点的id；如果有多个源节点，逗号分隔；如果是all表示集群内所有主节点 --to: 需要迁移的目标节点id，目标节点只能写一个 --slots:需要迁移的槽的总数量 --yes:当打印出reshared执行计划时，是否需要用户输入yes确认后再执行reshared --timeout:控制每次migrate操作的超时时间，默认60,000毫秒 --pipeline:控制每次批量迁移键的数量，默认10 收缩集群 下线迁移槽 如果下线的节点持有槽，则下线节点需要把自己负责的槽迁移到其他节点；通过redis-trib.rb reshared命令来完成 忘记节点 使用redis-trib.rb del-node工具来完成 请求路由 MOVED重定向 在集群模式下，redis接受任何键相关命令时首先计算出对应的槽，根据槽找出对应节点； 如果节点是本身，则执行键命令； 否则回复MOVED重定向错误，通知客户端请求正确的节点； 这个过程称为MOVED重定向 如果使用redis-cli，可以加入-c参数支持自动重定向 redis-cli -p 6379 -c smart客户端 原理：smart客户端通过在内部维护slot->node的映射关系，本地就可以实现键到节点的查找，从而避免MOVED重定向带来的二次操作，保证IO效率的最大化 各个语言的客户端可在官网查找: http://redis.io/clients 初始化过程： 客户端初始化是会选择一个运行节点，初始化槽和节点的映射关系； 解析cluster slots结果缓存在本地，并为每个节点创建唯一的连接池； 键执行流程 计算slot并根据slots缓存获取目标节点连接，发送命令 如果出现连接错误，使用随机连接重新执行键命令， 捕获到MOVED重定向错误时，使用cluster slots命令更新slots缓存 重复1～3步，直到命令成功（超过5次未成功则报告异常） ASK重定向 客户端ASk重定向流程： redis集群支持在线迁移槽和数据来完成水平伸缩，当slot对应的数据重源节点到目标节点的迁移过程中，客户端需要做到智能识别，保证键命令可正常执行； 例如当一个slot数据从源节点迁移到目标节点时，期间可能出现一部分数据在源节点，而另一部分在目标节点； 当出现上述情况时，客户端键命令执行流程将发生变化： 客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接执行并返回结果给客户端 如果键对象不存在，则可能存在于目标节点，这时源节点会回复ACK重定向异常 客户端从ASK重定向异常提取出目标节点信息，发送asking命令到目标节点打开客户端连接表示，再执行键命令；如果存在则执行，不存在则返回不存在信息 ASk重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此智能时临时性的重定向，客户端不会更新slots缓存； 但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此此时需要更新slots缓存 故障转移 故障发现 1. 主观下线(pfail) 指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判 流程： 节点a发送ping给节点b，如果收到pong则正常，a更新最近一次与b的通信时间 如果节点a与节点b通信出现问题则断开连接，下次会进行重连，如果一直通信失败，则节点a记录的与节点b的最后通信时间将无法更新 节点a内的定时任务检测到与节点b最后通信时间高于cluster-node-timeout时，更新本地对节点b的状态为主观下线 当某个节点判断另一个节点主观下线后，相应的节点状态会随消息在集群内传播； 当接收接收发现消息体中含有主观下线的节点状态时，会将故障节点保存到本地的下线报告链表中； 通过Gossip消息传播，集群内节点不断收集到故障节点的下线报告。当半数以上持有槽的主节点都标记某个节点主观下线时，触发客观下线流程； 2. 客观下线(fail) 指标记一个节点真正的下线；集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移 故障恢复 故障节点变为客观下线后，如果下线节点是持有槽的主节点，则需要在它的从节点中选出一个替换他，从而保证集群的高可用 流程 资格检查 准备选举时间 发起选举 选举投票 替换故障节点 集群运维 集群完成性 为了保证集群完整性，默认情况下集群中16384个槽任何一个没有指派到节点时整个集群都不可用，执行任何命令都会返回操作 但是当持有槽的主节点下线时，从故障发现到自动完成转移期间整个集群时不可用状态，对于大多数业务无法容忍这种情况，因此建议将cluster-require-full-coverage设置为no，当主节点故障时只影响它负责槽的相关命令，不影响其他主节点的可用性 带宽消耗 集群内Gossip消息通信本身会消耗带宽，因此官方建议集群最大规模在1000以内； 在满足业务需要的情况下尽量避免大集群 pub/sub广播问题 在集群模式下publish命令会向所有节点进行广播，造成每条publish数据都会在集群内所有节点传播一次，加重带宽负担； 针对这种情况建议使用sentinel结构专门用于pub/sub功能 集群倾斜 数据倾斜 如：节点和槽分配不均，不同槽对应键数量差异过大等； 使用redis-trib.rb info {host:ip}进行定位 可以使用redis-trib.rb rebalance进行平衡 请求倾斜集群读写分离 只读连接 读写分离 手动故障转移 redis集群工具：redis-trib.rb "},"case/":{"url":"case/","title":"应用案例","keywords":"","body":"应用案例应用案例 "},"case/cache.html":{"url":"case/cache.html","title":"缓存","keywords":"","body":"缓存缓存 "},"devops/":{"url":"devops/","title":"开发运维","keywords":"","body":"开发运维开发运维 "},"config/":{"url":"config/","title":"配置","keywords":"","body":"配置配置 "}}